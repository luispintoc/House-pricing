{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from scipy.stats import uniform, loguniform\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Lasso, LinearRegression, BayesianRidge, Ridge, ElasticNet\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "import warnings\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "df_train = pd.read_csv('input/train.csv')\n",
    "df_train['Train/Test'] = np.zeros(len(df_train.index))\n",
    "df_test = pd.read_csv('input/test.csv')\n",
    "df_test['Train/Test'] = np.ones(len(df_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing\n",
    "\n",
    "We will follow the guidelines stablish in the EDA script. Exactly the same transformations/imputations/deletions explained there are performed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array to transform\n",
    "to_box_cox = []\n",
    "to_yeoj = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SalePrice'] = np.log(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 MSZoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df_train, df_test]).reset_index(drop=True)\n",
    "df_full['MSZoning'] = df_full.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "df_train = df_full[df_full['Train/Test']==0].reset_index(drop=True)\n",
    "df_test = df_full[df_full['Train/Test']==1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 MSSubClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df_train, df_test]).reset_index(drop=True)\n",
    "df_full = df_full.replace({'MSSubClass':150}, df_full.groupby('MSZoning')['MSSubClass'].median()['RL'])\n",
    "df_train = df_full[df_full['Train/Test']==0].reset_index(drop=True)\n",
    "df_test = df_full[df_full['Train/Test']==1].reset_index(drop=True)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['MSZoning','MSSubClass'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['MSZoning','MSSubClass'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop([934, 1298], axis=0)\n",
    "df_full = pd.concat([df_train, df_test]).reset_index(drop=True)\n",
    "df_full[\"LotFrontage\"] = df_full.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "df_train = df_full[df_full['Train/Test']==0].reset_index(drop=True)\n",
    "df_test = df_full[df_full['Train/Test']==1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 LotArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['LotArea'] = df_train['LotArea'].apply(lambda x: 100000 if x > 100000 else x)\n",
    "df_train['LotArea'] = np.log(df_train['LotArea'])\n",
    "df_test['LotArea'] = np.log(df_test['LotArea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Alley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Alley'] = df_train['Alley'].fillna(\"NoAlley\")\n",
    "df_test['Alley'] = df_test['Alley'].fillna(\"NoAlley\")\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['Alley'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Alley'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 LotShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['LotShape'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['LotShape'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 LandContour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['LandContour'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['LandContour'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['Utilities'], axis=1)\n",
    "df_test = df_test.drop(['Utilities'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 LotConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['LotConfig'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['LotConfig'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 LandSlope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['LandSlope'] = df_train['LandSlope'].apply(lambda x:'Mod' if x in ['Mod', 'Sev'] else 'Gtl')\n",
    "df_test['LandSlope'] = df_test['LandSlope'].apply(lambda x:'Mod' if x in ['Mod', 'Sev'] else 'Gtl')\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['LandSlope'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['LandSlope'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborhood_loc(df):\n",
    "    df[\"North\"] = df[\"Neighborhood\"].apply(lambda x: 1 if x in [\"Blmngtn\", \"BrDale\", \"ClearCr\", \"Gilbert\",  \"Names\", \"NoRidge\", \n",
    "                                                                  \"NPkVill\", \"NWAmes\", \"NoRidge\", \"NridgHt\", \"Sawyer\", \"Somerst\", \n",
    "                                                                  \"StoneBr\", \"Veenker\", \"NridgHt\"] else 0)\n",
    "\n",
    "    df[\"South\"] = df[\"Neighborhood\"].apply(lambda x: 1 if x in [\"Blueste\", \"Edwards\", \"Mitchel\", \"MeadowV\", \n",
    "                                                                  \"SWISU\", \"IDOTRR\", \"Timber\"] else 0)\n",
    "\n",
    "    df[\"Downtown\"] = df[\"Neighborhood\"].apply(lambda x: 1 if x in [\"BrkSide\", \"Crawfor\", \"OldTown\", \"CollgCr\"] else 0)\n",
    "\n",
    "    df[\"East\"] = df[\"Neighborhood\"].apply(lambda x: 1 if x in [\"IDOTRR\", \"Mitchel\"] else 0)\n",
    "\n",
    "    df[\"West\"] = df[\"Neighborhood\"].apply(lambda x: 1 if x in [\"Edwards\", \"NWAmes\", \"SWISU\", \"Sawyer\", \"SawyerW\"] else 0)\n",
    "    \n",
    "    df = df.drop(['Neighborhood'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train = neighborhood_loc(df_train)\n",
    "df_test = neighborhood_loc(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13 Condition1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Condition1'] = df_train['Condition1'].apply(lambda x:'RRNe' if x in ['RRAe']\n",
    "                                                     else ('PosN' if x in ['PosA'] \n",
    "                                                        else ('RRNn' if x in ['RRAn'] else x)\n",
    "                                                          ))\n",
    "df_test['Condition1'] = df_test['Condition1'].apply(lambda x:'RRNe' if x in ['RRAe']\n",
    "                                                     else ('PosN' if x in ['PosA'] \n",
    "                                                        else ('RRNn' if x in ['RRAn'] else x)\n",
    "                                                          ))\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['Condition1'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Condition1'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14 Condition2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['Condition2'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Condition2'], drop_first=True)\n",
    "\n",
    "df_train = df_train.drop(['Condition2_RRAn', 'Condition2_RRNn', 'Condition2_RRAe'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15 BldgType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['BldgType'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['BldgType'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.16 HouseStyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['HouseStyle'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['HouseStyle'], drop_first=True)\n",
    "\n",
    "df_train = df_train.drop(['HouseStyle_2.5Fin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.17 OverallQual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need it for the 'MasVnrArea' feat, so we will get dummies later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.18 OverallCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Total_Home_Quality'] = df_train['OverallQual'] + df_train['OverallCond']\n",
    "df_test['Total_Home_Quality'] = df_test['OverallQual'] + df_test['OverallCond']\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['Total_Home_Quality'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Total_Home_Quality'], drop_first=True)\n",
    "\n",
    "df_train = df_train.drop(['OverallCond'], axis=1)\n",
    "df_test = df_test.drop(['OverallCond'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.19 YearRemodAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_restoration(df):\n",
    "    df[\"RestorationAge\"] = df[\"YearRemodAdd\"] - df[\"YearBuilt\"]\n",
    "    df[\"HasRestoration\"] = df[\"RestorationAge\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "    df = df.drop(['RestorationAge', 'YearRemodAdd'], axis=1)\n",
    "    return df\n",
    "\n",
    "df_train = has_restoration(df_train)\n",
    "df_test = has_restoration(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.20 YearBuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['YearBuilt'] = df_train['YearBuilt'].apply(lambda x: 0 if x<1980 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.21 RoofStyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['RoofStyle'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['RoofStyle'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.22 RoofMatl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['RoofMatl'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['RoofMatl'], drop_first=True)\n",
    "\n",
    "df_train = df_train.drop(['RoofMatl_Metal','RoofMatl_Membran','RoofMatl_Roll'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.23 Exterior1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Exterior1st'].fillna('VinylSd', inplace=True)\n",
    "df_train = pd.get_dummies(df_train, columns=['Exterior1st'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Exterior1st'], drop_first=True)\n",
    "\n",
    "df_train = df_train.drop(['Exterior1st_Stone','Exterior1st_BrkComm','Exterior1st_ImStucc','Exterior1st_CBlock','Exterior1st_AsphShn'], axis=1)\n",
    "df_test = df_test.drop(['Exterior1st_BrkComm','Exterior1st_CBlock','Exterior1st_AsphShn'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.24 Exterior2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Exterior2nd'].fillna('VinylSd', inplace=True)\n",
    "df_train = pd.get_dummies(df_train, columns=['Exterior2nd'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Exterior2nd'], drop_first=True)\n",
    "\n",
    "df_train = df_train.drop(['Exterior2nd_Stone','Exterior2nd_Brk Cmn','Exterior2nd_CBlock','Exterior2nd_AsphShn','Exterior2nd_Other'], axis=1)\n",
    "df_test = df_test.drop(['Exterior2nd_Stone','Exterior2nd_Brk Cmn','Exterior2nd_CBlock','Exterior2nd_AsphShn'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.25 MasVnrType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['MasVnrType'], axis=1)\n",
    "df_test = df_test.drop(['MasVnrType'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.26 MasVnrArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df_train, df_test]).reset_index(drop=True)\n",
    "df_full[\"MasVnrArea\"] = df_full.groupby(\"OverallQual\")[\"MasVnrArea\"].apply(lambda x: x.fillna(x.median()))\n",
    "df_train = df_full[df_full['Train/Test']==0].reset_index(drop=True)\n",
    "df_test = df_full[df_full['Train/Test']==1].reset_index(drop=True)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['OverallQual'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['OverallQual'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_yeoj.append('MasVnrArea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.27 ExterQual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['ExterQual'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['ExterQual'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.28 ExterCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ExterCond'] = df_train['ExterCond'].apply(lambda x:'Fa' if x in ['Po', 'Fa'] else x)\n",
    "df_train['ExterCond'] = df_train['ExterCond'].apply(lambda x:'Ex' if x in ['Ex', 'Gd'] else x)\n",
    "df_test['ExterCond'] = df_test['ExterCond'].apply(lambda x:'Fa' if x in ['Po', 'Fa'] else x)\n",
    "df_test['ExterCond'] = df_test['ExterCond'].apply(lambda x:'Ex' if x in ['Ex', 'Gd'] else x)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['ExterCond'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['ExterCond'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.29 Foundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['Foundation'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Foundation'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.30 Basement features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_bsmt_feat(df):\n",
    "    mask = (df['TotalBsmtSF']==0)\n",
    "    df.loc[df['BsmtQual'].isnull() & mask, 'BsmtQual'] = 'NoBsmt'\n",
    "    df.loc[df['BsmtCond'].isnull() & mask, 'BsmtCond'] = 'NoBsmt'\n",
    "    df.loc[df['BsmtExposure'].isnull() & mask, 'BsmtExposure'] = 'NoBsmt'\n",
    "\n",
    "    df.loc[df['BsmtFinType1'].isnull() & (df['BsmtFinSF1']==0), 'BsmtFinType1'] = 'NoBsmt'\n",
    "    df.loc[df['BsmtFinType2'].isnull() & (df['BsmtFinSF2']==0), 'BsmtFinType2'] = 'NoBsmt'\n",
    "    \n",
    "    df.loc[df['BsmtFinType1'].isnull() & (df['BsmtUnfSF']>0), 'BsmtFinType1'] = 'Unf'\n",
    "    df.loc[df['BsmtFinType2'].isnull() & (df['BsmtUnfSF']>0), 'BsmtFinType2'] = 'Unf'\n",
    "    return df\n",
    "\n",
    "df_train = impute_bsmt_feat(df_train)\n",
    "df_test = impute_bsmt_feat(df_test)\n",
    "\n",
    "df_test[\"BsmtFinSF1\"].fillna(df_train.groupby(\"1stFlrSF\")[\"BsmtFinSF1\"].median() , inplace=True)\n",
    "df_test[\"BsmtFinSF2\"].fillna(df_train.groupby(\"1stFlrSF\")[\"BsmtFinSF2\"].median() , inplace=True)\n",
    "df_test[\"BsmtUnfSF\"].fillna(df_train.groupby(\"1stFlrSF\")[\"BsmtUnfSF\"].median() , inplace=True)\n",
    "df_test[\"TotalBsmtSF\"].fillna(df_train.groupby(\"1stFlrSF\")[\"TotalBsmtSF\"].median() , inplace=True)\n",
    "\n",
    "df_test[\"BsmtQual\"].fillna(df_train[\"BsmtQual\"].mode().iloc[0] , inplace=True)\n",
    "df_test[\"BsmtCond\"].fillna(df_train[\"BsmtCond\"].mode().iloc[0] , inplace=True)\n",
    "df_train[\"BsmtExposure\"].fillna(df_train[\"BsmtExposure\"].mode().iloc[0] , inplace=True)\n",
    "df_test[\"BsmtExposure\"].fillna(df_train[\"BsmtExposure\"].mode().iloc[0] , inplace=True)\n",
    "df_test[\"BsmtFinType1\"].fillna(df_train[\"BsmtFinType1\"].mode().iloc[0] , inplace=True)\n",
    "df_test[\"BsmtFinType2\"].fillna(df_train[\"BsmtFinType2\"].mode().iloc[0] , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']\n",
    "df_train = pd.get_dummies(df_train, columns=bsmt_feat, drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=bsmt_feat, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_yeoj.append('BsmtFinSF1')\n",
    "to_yeoj.append('BsmtFinSF2')\n",
    "to_yeoj.append('BsmtUnfSF')\n",
    "to_yeoj.append('TotalBsmtSF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.31 Heating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['Heating'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Heating'], drop_first=True)\n",
    "\n",
    "df_train = df_train.drop(['Heating_OthW', 'Heating_GasA'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.32 HeatingQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['HeatingQC'] = df_train['HeatingQC'].apply(lambda x:'Fa' if x in ['Po', 'Fa'] else x)\n",
    "df_test['HeatingQC'] = df_test['HeatingQC'].apply(lambda x:'Fa' if x in ['Po', 'Fa'] else x)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['HeatingQC'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['HeatingQC'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.33 CentralAir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['CentralAir'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['CentralAir'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.34 Electrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\n",
    "df_train = df_train.drop(df_train.loc[df_train['Electrical']=='Mix'].index)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['Electrical'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Electrical'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.35 1stFlrSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_box_cox.append('1stFlrSF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.36 2ndFlrSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TotalFlrSF'] = df_train['1stFlrSF'] + df_train['2ndFlrSF']\n",
    "df_test['TotalFlrSF'] = df_test['1stFlrSF'] + df_test['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['2ndFlr'] = df_train['2ndFlrSF'].apply(lambda x:'Y' if x > 0 else 'N')\n",
    "df_test['2ndFlr'] = df_test['2ndFlrSF'].apply(lambda x:'Y' if x > 0 else 'N')\n",
    "\n",
    "df_train = df_train.drop(['2ndFlrSF'], axis=1)\n",
    "df_test = df_test.drop(['2ndFlrSF'], axis=1)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['2ndFlr'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['2ndFlr'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.37 LowQualFinSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['LowQualFin'] = df_train['LowQualFinSF'].apply(lambda x:'Y' if x > 0 else 'N')\n",
    "df_test['LowQualFin'] = df_test['LowQualFinSF'].apply(lambda x:'Y' if x > 0 else 'N')\n",
    "\n",
    "df_train = df_train.drop(['LowQualFinSF'], axis=1)\n",
    "df_test = df_test.drop(['LowQualFinSF'], axis=1)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['LowQualFin'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['LowQualFin'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.38 GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(df_train.loc[(df_train['GrLivArea'] > 4000) & (df_train['SalePrice'] < 300000)].index)\n",
    "to_box_cox.append('GrLivArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"TotalArea\"] = df_train[\"TotalBsmtSF\"] + df_train[\"GrLivArea\"]\n",
    "df_test[\"TotalArea\"] = df_test[\"TotalBsmtSF\"] + df_test[\"GrLivArea\"]\n",
    "to_box_cox.append('TotalArea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.39 BsmtFullBath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['BsmtFullBath'] = df_train['BsmtFullBath'].apply(lambda x:2.0 if x in [2.0, 3.0] else x)\n",
    "df_test['BsmtFullBath'] = df_test['BsmtFullBath'].apply(lambda x:2.0 if x in [2.0, 3.0] else x)\n",
    "\n",
    "df_test.loc[df_test['BsmtFullBath'].isnull() & (df_test['TotalBsmtSF']==0), 'BsmtFullBath'] = 0.0\n",
    "df_test.loc[df_test['BsmtFullBath'].isnull() & (df_test['BsmtUnfSF']==0), 'BsmtFullBath'] = 0.0\n",
    "\n",
    "df_test['BsmtFullBath'].fillna(0.0, inplace=True)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['BsmtFullBath'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['BsmtFullBath'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.40 BsmtHalfBath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['BsmtHalfBath'].isnull() & (df_test['TotalBsmtSF']==0), 'BsmtHalfBath'] = 0.0\n",
    "df_test.loc[df_test['BsmtHalfBath'].isnull() & (df_test['BsmtUnfSF']==0), 'BsmtHalfBath'] = 0.0\n",
    "df_test['BsmtHalfBath'].fillna(0.0, inplace=True)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['BsmtHalfBath'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['BsmtHalfBath'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.41 FullBath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['FullBath'] = df_test['FullBath'].apply(lambda x:3 if x in [3, 4] else x)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['FullBath'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['FullBath'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.42 HalfBath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['HalfBath'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['HalfBath'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.43 BedroomAbvGr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(df_train.loc[df_train['BedroomAbvGr'] == 8].index)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['BedroomAbvGr'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['BedroomAbvGr'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.44 KitchenAbvGr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['KitchenAbvGr'] = df_train['KitchenAbvGr'].apply(lambda x:2 if x in [2, 3] else 1)\n",
    "df_test['KitchenAbvGr'] = df_test['KitchenAbvGr'].apply(lambda x:2 if x in [2, 3] else 1)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['KitchenAbvGr'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['KitchenAbvGr'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.45 KitchenQual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['KitchenQual'].fillna('TA', inplace=True)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['KitchenQual'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['KitchenQual'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.46 TotRmsAbvGrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TotRmsAbvGrd'] = df_train['TotRmsAbvGrd'].apply(lambda x:12 if x>=12 else x)\n",
    "df_train['TotRmsAbvGrd'] = df_train['TotRmsAbvGrd'].apply(lambda x:3 if x<=3 else x)\n",
    "df_test['TotRmsAbvGrd'] = df_test['TotRmsAbvGrd'].apply(lambda x:12 if x>=12 else x)\n",
    "df_test['TotRmsAbvGrd'] = df_test['TotRmsAbvGrd'].apply(lambda x:3 if x<=3 else x)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['TotRmsAbvGrd'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['TotRmsAbvGrd'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.47 Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Functional'] = df_train['Functional'].apply(lambda x:'NotTyp' if x!='Typ' else 'Typ')\n",
    "df_test['Functional'] = df_test['Functional'].apply(lambda x:'NotTyp' if x!='Typ' else 'Typ')\n",
    "df_test['Functional'].fillna('Typ', inplace=True)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['Functional'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Functional'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.48 Fireplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Fireplaces'] = df_train['Fireplaces'].apply(lambda x:'2+' if x>=2 else x)\n",
    "df_test['Fireplaces'] = df_test['Fireplaces'].apply(lambda x:'2+' if x>=2 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.49 FireplaceQu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['FireplaceQu'].isnull() & (df_train['Fireplaces']==0), 'FireplaceQu'] = 'NoFire'\n",
    "df_test.loc[df_test['FireplaceQu'].isnull() & (df_test['Fireplaces']==0), 'FireplaceQu'] = 'NoFire'\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['Fireplaces'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Fireplaces'], drop_first=True)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['FireplaceQu'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['FireplaceQu'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.50 Garage features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_garage_feat(df):\n",
    "    mask = (df['GarageArea']==0)\n",
    "    df.loc[df['GarageType'].isnull() & mask, 'GarageType'] = 'NoGarage'\n",
    "    df.loc[df['GarageFinish'].isnull() & mask, 'GarageFinish'] = 'NoGarage'\n",
    "    df.loc[df['GarageQual'].isnull() & mask, 'GarageQual'] = 'NoGarage'\n",
    "    df.loc[df['GarageCond'].isnull() & mask, 'GarageCond'] = 'NoGarage'\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = impute_garage_feat(df_train)\n",
    "df_test = impute_garage_feat(df_test)\n",
    "\n",
    "df_test.loc[df_test['GarageFinish'].isnull(), 'GarageFinish'] = 'Unf'\n",
    "df_test.loc[df_test['GarageQual'].isnull(), 'GarageQual'] = 'Fa'\n",
    "df_test.loc[df_test['GarageCond'].isnull(), 'GarageCond'] = 'Fa'\n",
    "df_test['GarageCars'].fillna(1, inplace=True)\n",
    "df_test['GarageArea'].fillna(360, inplace=True)\n",
    "\n",
    "to_yeoj.append('GarageArea')\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['GarageType','GarageFinish','GarageQual','GarageCond', 'GarageCars'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['GarageType','GarageFinish','GarageQual','GarageCond', 'GarageCars'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['GarageYrBlt'].fillna(0, inplace=True)\n",
    "df_test['GarageYrBlt'].fillna(0, inplace=True)\n",
    "\n",
    "def garage_Y_N(df):\n",
    "    df['Garage_No'] = df['GarageYrBlt'].apply(lambda x:1 if x==0 else 0)\n",
    "    df['Garage_40s'] = df['GarageYrBlt'].apply(lambda x:1 if x<=1940 else 0)\n",
    "    df['Garage_40-60'] = df['GarageYrBlt'].apply(lambda x:1 if ((x>1940) & (x<=1960)) else 0)\n",
    "    df['Garage_60-80'] = df['GarageYrBlt'].apply(lambda x:1 if ((x>1960) & (x<=1980)) else 0)\n",
    "    df['Garage_80-00'] = df['GarageYrBlt'].apply(lambda x:1 if ((x>1980) & (x<=2000)) else 0)\n",
    "    df['Garage_00s'] = df['GarageYrBlt'].apply(lambda x:1 if x>2000 else 0)\n",
    "    df = df.drop(['GarageYrBlt'], axis=1)\n",
    "    return df\n",
    "\n",
    "df_train = garage_Y_N(df_train)\n",
    "df_test = garage_Y_N(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.51 PavedDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['PavedDrive'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['PavedDrive'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.52 WoodDeckSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WoodDeck_Y_N(df):\n",
    "    df['WoodDeck'] = df['WoodDeckSF'].apply(lambda x:1 if x>0 else 0)\n",
    "    df = df.drop(['WoodDeckSF'], axis=1)\n",
    "    return df\n",
    "df_train = WoodDeck_Y_N(df_train)\n",
    "df_test = WoodDeck_Y_N(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.53 OpenPorchSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenPorch_Y_N(df):\n",
    "    df['OpenPorch'] = df['OpenPorchSF'].apply(lambda x:1 if x>0 else 0)\n",
    "    df = df.drop(['OpenPorchSF'], axis=1)\n",
    "    return df\n",
    "df_train = OpenPorch_Y_N(df_train)\n",
    "df_test = OpenPorch_Y_N(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.54 EnclosedPorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EnclosedPorch_Y_N(df):\n",
    "    df['EnclosedPorch'] = df['EnclosedPorch'].apply(lambda x:1 if x>0 else 0)\n",
    "    return df\n",
    "df_train = EnclosedPorch_Y_N(df_train)\n",
    "df_test = EnclosedPorch_Y_N(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.55 3SsnPorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SsnPorch_Y_N(df):\n",
    "    df['3SsnPorch'] = df['3SsnPorch'].apply(lambda x:1 if x>0 else 0)\n",
    "    return df\n",
    "df_train = SsnPorch_Y_N(df_train)\n",
    "df_test = SsnPorch_Y_N(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.56 PoolArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pool_Y_N(df):\n",
    "    df['Pool'] = df['PoolArea'].apply(lambda x:1 if x>0 else 0)\n",
    "    return df\n",
    "df_train = Pool_Y_N(df_train)\n",
    "df_test = Pool_Y_N(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.57 PoolQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['PoolQC'], axis=1)\n",
    "df_test = df_test.drop(['PoolQC'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.58 Fence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Fence'].fillna('NoFence', inplace=True)\n",
    "df_test['Fence'].fillna('NoFence', inplace=True)\n",
    "\n",
    "df_train['Fence'] = df_train['Fence'].apply(lambda x:0 if x=='NoFence' else 1)\n",
    "df_test['Fence'] = df_test['Fence'].apply(lambda x:0 if x=='NoFence' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.59 MiscFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['MiscFeature'].fillna('NoMisc', inplace=True)\n",
    "df_test['MiscFeature'].fillna('NoMisc', inplace=True)\n",
    "\n",
    "df_train['MiscFeature'] = df_train['MiscFeature'].apply(lambda x:0 if x=='NoMisc' else 1)\n",
    "df_test['MiscFeature'] = df_test['MiscFeature'].apply(lambda x:0 if x=='NoMisc' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.60 MiscVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['MiscVal'], axis=1)\n",
    "df_test = df_test.drop(['MiscVal'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.61 MoSold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season(df):\n",
    "    df[\"Season\"] = df[\"MoSold\"].apply(lambda x: \"Winter\" if x in [12, 1, 2] else\n",
    "                                       (\"Spring\" if x in [3, 4, 5] else\n",
    "                                       (\"Summer\" if x in [6, 7, 8] else \"Fall\")))\n",
    "    df = df.drop(['MoSold'], axis=1)\n",
    "    return df\n",
    "\n",
    "df_train = season(df_train)\n",
    "df_test = season(df_test)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['Season'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Season'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.62 YrSold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['YrSold'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['YrSold'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.63 SaleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SaleType'] = df_train['SaleType'].apply(lambda x:'Warranty' if x in ['WD', 'CWD', 'WVWD'] else x)\n",
    "df_train['SaleType'] = df_train['SaleType'].apply(lambda x:'Contract' if x in ['Con', 'ConLw', 'ConLI', 'ConLD', 'Oth'] else x)\n",
    "df_test['SaleType'] = df_test['SaleType'].apply(lambda x:'Warranty' if x in ['WD', 'CWD', 'WVWD'] else x)\n",
    "df_test['SaleType'] = df_test['SaleType'].apply(lambda x:'Contract' if x in ['Con', 'ConLw', 'ConLI', 'ConLD', 'Oth'] else x)\n",
    "\n",
    "df_test['SaleType'].fillna('Warranty', inplace=True)\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['SaleType'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['SaleType'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.64 SaleCondition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['SaleCondition'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['SaleCondition'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.65 Street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['Street'], axis=1)\n",
    "df_test = df_test.drop(['Street'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['Train/Test', 'Id'], axis=1)\n",
    "df_test = df_test.drop(['Train/Test', 'Id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['SalePrice']\n",
    "x_train = df_train.drop(['SalePrice'], axis=1)\n",
    "x_test = df_test\n",
    "\n",
    "num_feat = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', 'TotalFlrSF', 'GrLivArea', 'TotalArea', 'GarageArea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the evaluation function and cross validation scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 6, shuffle = True, random_state = 42)\n",
    "\n",
    "# Define metric\n",
    "def nrmse(y_true, y_pred):\n",
    "    return -1.0*np.sqrt(np.mean((y_true-y_pred)**2))\n",
    "\n",
    "neg_rmse = make_scorer(nrmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 No feature selection\n",
    "\n",
    "No feature selection will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 257 features.\n"
     ]
    }
   ],
   "source": [
    "print('There are %s features.' %len(x_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "            transformers = [\n",
    "                            ('box-cox', PowerTransformer(method='box-cox'), to_box_cox),\n",
    "                            ('yeo-j', PowerTransformer(method='yeo-johnson'), to_yeoj),\n",
    "            ], remainder='passthrough'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'lasso__alpha': 4.121424789297808e-05}\n",
      "Best Score:  0.11695986582437551\n"
     ]
    }
   ],
   "source": [
    "model = Lasso(random_state=42)\n",
    "params = {\n",
    "    'lasso__alpha': loguniform(1e-6, 10)\n",
    "        }\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'ridge__alpha': 1.6559787569396243}\n",
      "Best Score:  0.115591012626049\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "params = {\n",
    "    'ridge__alpha': loguniform(1e-6, 10)\n",
    "        }\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ElasticNet model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'elasticnet__alpha': 0.00022507296536296623, 'elasticnet__l1_ratio': 0.9584015494353345}\n",
      "Best Score:  0.11345933111638329\n"
     ]
    }
   ],
   "source": [
    "model = ElasticNet()\n",
    "params = {\n",
    "    'elasticnet__alpha': loguniform(1e-5, 10),\n",
    "    'elasticnet__l1_ratio': uniform(0, 1),\n",
    "        }\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBRegressor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=41, objective ='reg:squarederror', verbosity=0)\n",
    "params = {\n",
    "    'xgbregressor__n_estimators': (1000, 1500, 2000, 25000, 3000),\n",
    "    'xgbregressor__learning_rate': loguniform(5e-4, 0.5),\n",
    "    'xgbregressor__gamma': uniform(0.05, 0.5),\n",
    "    'xgbregressor__reg_alpha': uniform(0.1, 1),\n",
    "    'xgbregressor__reg_lambda': uniform(0.1, 1),\n",
    "    'xgbregressor__max_depth': (3, 4)\n",
    "        }\n",
    "# pipeline = make_pipeline(preprocess, model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "# grid_search.fit(x_train, y_train)\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'xgbregressor__gamma': 0.09527308751772857, 'xgbregressor__learning_rate': 0.0259820513280639, 'xgbregressor__max_depth': 3, 'xgbregressor__n_estimators': 1000, 'xgbregressor__reg_alpha': 0.3436203269072283, 'xgbregressor__reg_lambda': 0.48876374229779784}\n",
    "\n",
    "Best Score:  0.13519815452348424"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LGBM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(objective='regression', verbosity=-1)\n",
    "params = {\n",
    "    'lgbmregressor__learning_rate': uniform(1e-3, 1),\n",
    "    'lgbmregressor__n_estimators': (500, 600, 700, 800, 1000),\n",
    "    'lgbmregressor__bagging_fraction': uniform(0, 0.99),\n",
    "    'lgbmregressor__bagging_fraction': uniform(0, 0.99),\n",
    "    'lgbmregressor__num_leaves': (25, 31, 40),\n",
    "    'lgbmregressor__reg_lambda': uniform(1e-7, 1e-3),\n",
    "    'lgbmregressor__min_sum_hessian_in_leaf': uniform(1e-3, 1),\n",
    "        }\n",
    "# pipeline = make_pipeline(model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "# grid_search.fit(x_train, y_train)\n",
    "# print('\\n')\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'lgbmregressor__bagging_fraction': 0.6361919522766912, 'lgbmregressor__learning_rate': 0.03318417201151236, 'lgbmregressor__min_sum_hessian_in_leaf': 0.37634723590718155, 'lgbmregressor__n_estimators': 700, 'lgbmregressor__num_leaves': 25, 'lgbmregressor__reg_lambda': 0.0003117539669082681}\n",
    "\n",
    "Best Score:  0.12986865528676914"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoostRegressor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(eval_metric='RMSE', verbose=False)\n",
    "params = {\n",
    "    'catboostregressor__iterations': (1000, 2000, 3000),\n",
    "    'catboostregressor__learning_rate': uniform(5e-4, 5e-1),\n",
    "    'catboostregressor__depth': (4, 6, 10),\n",
    "    'catboostregressor__l2_leaf_reg': (1, 2, 3, 5, 9),\n",
    "        }\n",
    "# pipeline = make_pipeline(model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "# grid_search.fit(x_train, y_train)\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'catboostregressor__depth': 4, 'catboostregressor__iterations': 3000, 'catboostregressor__l2_leaf_reg': 9, 'catboostregressor__learning_rate': 0.023399871367886682}\n",
    "\n",
    "Best Score:  0.11993553047690914"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 XGB feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the XGBRegressor model to perform feature selection. Since this is a tree-based model, no transformations will be performed before the selection. However, the transformations will be passed to a pipeline next to the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_feat = XGBRegressor(random_state=41, objective ='reg:squarederror', verbosity=0).fit(x_train, y_train).feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 111 important features\n"
     ]
    }
   ],
   "source": [
    "xgb_imp_feat = []\n",
    "for feat,weight in zip(x_train.columns, xgb_feat):\n",
    "    if abs(weight) > 0:\n",
    "        xgb_imp_feat.append(feat)\n",
    "print('There are %d important features' %(len(xgb_imp_feat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = x_train[xgb_imp_feat]\n",
    "\n",
    "feat_box_cox = [i for i in xgb_imp_feat if i in to_box_cox]\n",
    "feat_yeo_j = [i for i in xgb_imp_feat if i in to_yeoj]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "            transformers = [\n",
    "                            ('box-cox', PowerTransformer(method='box-cox'), feat_box_cox),\n",
    "                            ('yeo-j', PowerTransformer(method='yeo-johnson'), feat_yeo_j),\n",
    "            ], remainder='passthrough'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'lasso__alpha': 0.00016345750833943296}\n",
      "Best Score:  0.11526221619060961\n"
     ]
    }
   ],
   "source": [
    "model = Lasso(random_state=42)\n",
    "params = {\n",
    "    'lasso__alpha': loguniform(1e-6, 10)\n",
    "        }\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "grid_search.fit(x_train_1, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'ridge__alpha': 8.358974890258594}\n",
      "Best Score:  0.11483172795898665\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "params = {\n",
    "    'ridge__alpha': loguniform(1e-6, 10)\n",
    "        }\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "grid_search.fit(x_train_1, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ElasticNet model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'elasticnet__alpha': 0.0022067854424386636, 'elasticnet__l1_ratio': 0.038233620689702374}\n",
      "Best Score:  0.11464005205787409\n"
     ]
    }
   ],
   "source": [
    "model = ElasticNet()\n",
    "params = {\n",
    "    'elasticnet__alpha': loguniform(1e-5, 10),\n",
    "    'elasticnet__l1_ratio': uniform(0, 1),\n",
    "        }\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "grid_search.fit(x_train_1, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBRegressor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'xgbregressor__gamma': 0.08301757681033752, 'xgbregressor__learning_rate': 0.05421890098255953, 'xgbregressor__max_depth': 3, 'xgbregressor__n_estimators': 25000, 'xgbregressor__reg_alpha': 0.29957088128617015, 'xgbregressor__reg_lambda': 0.24618230337678307}\n",
      "Best Score:  0.1331964346402534\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(random_state=41, objective ='reg:squarederror', verbosity=0)\n",
    "params = {\n",
    "    'xgbregressor__n_estimators': (1000, 1500, 2000, 25000, 3000),\n",
    "    'xgbregressor__learning_rate': loguniform(5e-4, 0.5),\n",
    "    'xgbregressor__gamma': uniform(0.05, 0.5),\n",
    "    'xgbregressor__reg_alpha': uniform(0.1, 1),\n",
    "    'xgbregressor__reg_lambda': uniform(0.1, 1),\n",
    "    'xgbregressor__max_depth': (3, 4)\n",
    "        }\n",
    "# pipeline = make_pipeline(preprocess, model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "# grid_search.fit(x_train_1, y_train)\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'xgbregressor__gamma': 0.08301757681033752, 'xgbregressor__learning_rate': 0.05421890098255953, 'xgbregressor__max_depth': 3, 'xgbregressor__n_estimators': 25000, 'xgbregressor__reg_alpha': 0.29957088128617015, 'xgbregressor__reg_lambda': 0.24618230337678307}\n",
    "\n",
    "Best Score:  0.1331964346402534\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LGBM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(objective='regression', verbosity=-1)\n",
    "params = {\n",
    "    'lgbmregressor__learning_rate': uniform(1e-3, 1),\n",
    "    'lgbmregressor__n_estimators': (500, 600, 700, 800, 1000),\n",
    "    'lgbmregressor__bagging_fraction': uniform(0, 0.99),\n",
    "    'lgbmregressor__bagging_fraction': uniform(0, 0.99),\n",
    "    'lgbmregressor__num_leaves': (25, 31, 40),\n",
    "    'lgbmregressor__reg_lambda': uniform(1e-7, 1e-3),\n",
    "    'lgbmregressor__min_sum_hessian_in_leaf': uniform(1e-3, 1),\n",
    "        }\n",
    "# pipeline = make_pipeline(model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "# grid_search.fit(x_train_1, y_train)\n",
    "# print('\\n')\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'lgbmregressor__bagging_fraction': 0.05164479555385946, 'lgbmregressor__learning_rate': 0.07109840352076369, 'lgbmregressor__min_sum_hessian_in_leaf': 0.29636690737374916, 'lgbmregressor__n_estimators': 1000, 'lgbmregressor__num_leaves': 25, 'lgbmregressor__reg_lambda': 0.0005797528786936516}\n",
    "\n",
    "Best Score:  0.1312689666954018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoostRegressor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(eval_metric='RMSE', verbose=False)\n",
    "params = {\n",
    "    'catboostregressor__iterations': (1000, 2000, 3000),\n",
    "    'catboostregressor__learning_rate': uniform(5e-4, 5e-1),\n",
    "    'catboostregressor__depth': (4, 6, 10),\n",
    "    'catboostregressor__l2_leaf_reg': (1, 2, 3, 5, 9),\n",
    "        }\n",
    "# pipeline = make_pipeline(model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "# grid_search.fit(x_train_1, y_train)\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'catboostregressor__depth': 4, 'catboostregressor__iterations': 3000, 'catboostregressor__l2_leaf_reg': 5, 'catboostregressor__learning_rate': 0.019780746569495578}\n",
    "\n",
    "Best Score:  0.1186680757340557"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 L1 feature selection\n",
    "\n",
    "We will use the lasso regressor, which uses L1 penalization, to select the most important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_preprocess = ColumnTransformer(\n",
    "            transformers = [\n",
    "                            ('box-cox', PowerTransformer(method='box-cox'), to_box_cox),\n",
    "                            ('yeo-j', PowerTransformer(method='yeo-johnson'), to_yeoj),\n",
    "            ], remainder='passthrough'\n",
    "                            )\n",
    "\n",
    "l1_pipeline = make_pipeline(l1_preprocess, RobustScaler())\n",
    "x_temp = l1_pipeline.fit_transform(x_train)\n",
    "\n",
    "lasso_feat = Lasso(alpha=0.0001).fit(x_temp, y_train).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 189 important features\n"
     ]
    }
   ],
   "source": [
    "lasso_imp_feat = []\n",
    "for feat,weight in zip(x_train.columns, lasso_feat):\n",
    "    if abs(weight) > 0:\n",
    "        lasso_imp_feat.append(feat)\n",
    "print('There are %d important features' %(len(lasso_imp_feat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = x_train[lasso_imp_feat]\n",
    "\n",
    "feat_box_cox = [i for i in lasso_imp_feat if i in to_box_cox]\n",
    "feat_yeo_j = [i for i in lasso_imp_feat if i in to_yeoj]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "            transformers = [\n",
    "                            ('box-cox', PowerTransformer(method='box-cox'), feat_box_cox),\n",
    "                            ('yeo-j', PowerTransformer(method='yeo-johnson'), feat_yeo_j),\n",
    "            ], remainder='passthrough'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'ridge__alpha': 2.8616761513773197, 'ridge__solver': 'auto'}\n",
      "Best Score:  0.1218971611774814\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "params = {\n",
    "    'ridge__alpha': loguniform(1e-6, 10),\n",
    "    'ridge__solver': ('auto', 'svd', 'cholesky', 'saga')\n",
    "        }\n",
    "\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "grid_search.fit(x_train_2, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBRegressor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=41, objective ='reg:squarederror', verbosity=0)\n",
    "params = {\n",
    "    'xgbregressor__n_estimators': (1000, 1500, 2000, 25000, 3000),\n",
    "    'xgbregressor__learning_rate': loguniform(5e-4, 0.5),\n",
    "    'xgbregressor__gamma': uniform(0.05, 0.5),\n",
    "    'xgbregressor__reg_alpha': uniform(0.1, 1),\n",
    "    'xgbregressor__reg_lambda': uniform(0.1, 1),\n",
    "    'xgbregressor__max_depth': (3, 4)\n",
    "        }\n",
    "# pipeline = make_pipeline(preprocess, model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "# grid_search.fit(x_train_2, y_train)\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'xgbregressor__gamma': 0.07030916262422844, 'xgbregressor__learning_rate': 0.08105143535678436, 'xgbregressor__max_depth': 4, 'xgbregressor__n_estimators': 25000, 'xgbregressor__reg_alpha': 0.3381315506176623, 'xgbregressor__reg_lambda': 0.4041300140020865}\n",
    "\n",
    "Best Score:  0.13554172204922954"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ElasticNet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'elasticnet__alpha': 0.0009094922056998939, 'elasticnet__l1_ratio': 0.34308539739809374}\n",
      "Best Score:  0.12119036303411447\n"
     ]
    }
   ],
   "source": [
    "model = ElasticNet()\n",
    "params = {\n",
    "    'elasticnet__alpha': loguniform(1e-5, 10),\n",
    "    'elasticnet__l1_ratio': uniform(0, 1),\n",
    "        }\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "grid_search.fit(x_train_2, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LGBM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(objective='regression', verbosity=-1)\n",
    "params = {\n",
    "    'lgbmregressor__learning_rate': uniform(1e-3, 1),\n",
    "    'lgbmregressor__n_estimators': (500, 600, 700, 800, 1000),\n",
    "    'lgbmregressor__bagging_fraction': uniform(0, 0.99),\n",
    "    'lgbmregressor__bagging_fraction': uniform(0, 0.99),\n",
    "    'lgbmregressor__num_leaves': (25, 31, 40),\n",
    "    'lgbmregressor__reg_lambda': uniform(1e-7, 1e-3),\n",
    "    'lgbmregressor__min_sum_hessian_in_leaf': uniform(1e-3, 1),\n",
    "        }\n",
    "# pipeline = make_pipeline(model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "# grid_search.fit(x_train_2, y_train)\n",
    "# print('\\n')\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'lgbmregressor__bagging_fraction': 0.6950996849623589, 'lgbmregressor__learning_rate': 0.02465579007128682, 'lgbmregressor__min_sum_hessian_in_leaf': 0.9537260060097682, 'lgbmregressor__n_estimators': 800, 'lgbmregressor__num_leaves': 25, 'lgbmregressor__reg_lambda': 0.000863609658339175}\n",
    "\n",
    "Best Score:  0.13197205818970756"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoostRegressor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(eval_metric='RMSE', verbose=False)\n",
    "params = {\n",
    "    'catboostregressor__iterations': (1000, 2000, 3000),\n",
    "    'catboostregressor__learning_rate': uniform(5e-4, 5e-1),\n",
    "    'catboostregressor__depth': (4, 6, 10),\n",
    "    'catboostregressor__l2_leaf_reg': (1, 2, 3, 5, 9),\n",
    "        }\n",
    "# pipeline = make_pipeline(model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "# grid_search.fit(x_train_2, y_train)\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'catboostregressor__depth': 6, 'catboostregressor__iterations': 1000, 'catboostregressor__l2_leaf_reg': 3, 'catboostregressor__learning_rate': 0.041935865828842345}\n",
    "\n",
    "Best Score:  0.12292981360635409"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Correlation between features and target\n",
    "\n",
    "Univariate linear regression tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_preprocess = ColumnTransformer(\n",
    "            transformers = [\n",
    "                            ('box-cox', PowerTransformer(method='box-cox'), to_box_cox),\n",
    "                            ('yeo-j', PowerTransformer(method='yeo-johnson'), to_yeoj),\n",
    "            ], remainder='passthrough'\n",
    "                            )\n",
    "\n",
    "fs_pipeline = make_pipeline(l1_preprocess, RobustScaler())\n",
    "x_temp = fs_pipeline.fit_transform(x_train)\n",
    "\n",
    "fs = SelectKBest(score_func=f_regression, k='all')\n",
    "fs_feat = fs.fit(x_temp, y_train).scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 868.801626\n",
      "Feature 1: 1694.116536\n",
      "Feature 2: 3024.823108\n",
      "Feature 3: 289.661172\n",
      "Feature 4: 91.851018\n",
      "Feature 5: 1.620084\n",
      "Feature 6: 70.844738\n",
      "Feature 7: 983.128217\n",
      "Feature 8: 1083.283267\n",
      "Feature 9: 5.095103\n",
      "Feature 10: 26.817870\n",
      "Feature 11: 0.245774\n",
      "Feature 12: 19.385611\n",
      "Feature 13: 20.309625\n",
      "Feature 14: 17.639548\n",
      "Feature 15: 1.097344\n",
      "Feature 16: 24.089310\n",
      "Feature 17: 22.042344\n",
      "Feature 18: 9.088293\n",
      "Feature 19: 1.839329\n",
      "Feature 20: 0.950927\n",
      "Feature 21: 4.766469\n",
      "Feature 22: 3.467173\n",
      "Feature 23: 2.866677\n",
      "Feature 24: 4.506430\n",
      "Feature 25: 14.798095\n",
      "Feature 26: 50.329216\n",
      "Feature 27: 71.896059\n",
      "Feature 28: 1.438900\n",
      "Feature 29: 13.653606\n",
      "Feature 30: 10.043938\n",
      "Feature 31: 42.828534\n",
      "Feature 32: 0.269888\n",
      "Feature 33: 2.800278\n",
      "Feature 34: 194.412659\n",
      "Feature 35: 59.746576\n",
      "Feature 36: 5.349859\n",
      "Feature 37: 0.312684\n",
      "Feature 38: 12.976248\n",
      "Feature 39: 4.617304\n",
      "Feature 40: 0.329734\n",
      "Feature 41: 40.019807\n",
      "Feature 42: 0.756339\n",
      "Feature 43: 4.950070\n",
      "Feature 44: 196.039765\n",
      "Feature 45: 52.119573\n",
      "Feature 46: 4.215794\n",
      "Feature 47: 50.823483\n",
      "Feature 48: 8.151124\n",
      "Feature 49: 16.645948\n",
      "Feature 50: 7.174567\n",
      "Feature 51: 0.910471\n",
      "Feature 52: 104.035290\n",
      "Feature 53: 13.584188\n",
      "Feature 54: 0.178523\n",
      "Feature 55: 17.978219\n",
      "Feature 56: 2.261270\n",
      "Feature 57: 0.100530\n",
      "Feature 58: 1.845098\n",
      "Feature 59: 279.028411\n",
      "Feature 60: 34.007262\n",
      "Feature 61: 0.048904\n",
      "Feature 62: 0.770827\n",
      "Feature 63: 10.672662\n",
      "Feature 64: 227.516717\n",
      "Feature 65: 23.095425\n",
      "Feature 66: 2.503083\n",
      "Feature 67: 128.516933\n",
      "Feature 68: 13.295979\n",
      "Feature 69: 19.685412\n",
      "Feature 70: 17.612423\n",
      "Feature 71: 17.611078\n",
      "Feature 72: 173.621355\n",
      "Feature 73: 0.589636\n",
      "Feature 74: 15.321277\n",
      "Feature 75: 45.350425\n",
      "Feature 76: 272.599157\n",
      "Feature 77: 1.350853\n",
      "Feature 78: 0.187352\n",
      "Feature 79: 0.000086\n",
      "Feature 80: 2.067380\n",
      "Feature 81: 20.309625\n",
      "Feature 82: 22.204359\n",
      "Feature 83: 8.918633\n",
      "Feature 84: 141.178402\n",
      "Feature 85: 197.275040\n",
      "Feature 86: 8.755480\n",
      "Feature 87: 292.494307\n",
      "Feature 88: 2.409888\n",
      "Feature 89: 0.010920\n",
      "Feature 90: 4.222826\n",
      "Feature 91: 11.105725\n",
      "Feature 92: 51.857426\n",
      "Feature 93: 3.578984\n",
      "Feature 94: 58.241181\n",
      "Feature 95: 0.055753\n",
      "Feature 96: 1.071226\n",
      "Feature 97: 22.637173\n",
      "Feature 98: 104.144062\n",
      "Feature 99: 100.355264\n",
      "Feature 100: 40.094535\n",
      "Feature 101: 8.978950\n",
      "Feature 102: 164.805009\n",
      "Feature 103: 91.200677\n",
      "Feature 104: 53.498523\n",
      "Feature 105: 6.037117\n",
      "Feature 106: 4.350461\n",
      "Feature 107: 9.493925\n",
      "Feature 108: 13.421566\n",
      "Feature 109: 26.307482\n",
      "Feature 110: 17.753467\n",
      "Feature 111: 23.214123\n",
      "Feature 112: 66.669202\n",
      "Feature 113: 89.814220\n",
      "Feature 114: 40.223719\n",
      "Feature 115: 839.952306\n",
      "Feature 116: 28.003818\n",
      "Feature 117: 63.309720\n",
      "Feature 118: 197.666749\n",
      "Feature 119: 232.241860\n",
      "Feature 120: 9.936581\n",
      "Feature 121: 110.789733\n",
      "Feature 122: 337.091091\n",
      "Feature 123: 190.150327\n",
      "Feature 124: 83.624144\n",
      "Feature 125: 53.758143\n",
      "Feature 126: 522.481122\n",
      "Feature 127: 803.827417\n",
      "Feature 128: 59.975564\n",
      "Feature 129: 22.339034\n",
      "Feature 130: 190.227832\n",
      "Feature 131: 573.328251\n",
      "Feature 132: 38.248635\n",
      "Feature 133: 0.304720\n",
      "Feature 134: 0.123689\n",
      "Feature 135: 34.542508\n",
      "Feature 136: 191.992305\n",
      "Feature 137: 61.240477\n",
      "Feature 138: 436.293397\n",
      "Feature 139: 17.240587\n",
      "Feature 140: 61.240477\n",
      "Feature 141: 6.458884\n",
      "Feature 142: 26.777184\n",
      "Feature 143: 111.906606\n",
      "Feature 144: 4.176965\n",
      "Feature 145: 80.247900\n",
      "Feature 146: 61.240477\n",
      "Feature 147: 25.556437\n",
      "Feature 148: 344.041074\n",
      "Feature 149: 10.424647\n",
      "Feature 150: 61.240477\n",
      "Feature 151: 27.290188\n",
      "Feature 152: 12.398014\n",
      "Feature 153: 3.880396\n",
      "Feature 154: 0.011694\n",
      "Feature 155: 0.596355\n",
      "Feature 156: 61.240477\n",
      "Feature 157: 1.185588\n",
      "Feature 158: 22.976601\n",
      "Feature 159: 0.974102\n",
      "Feature 160: 33.671414\n",
      "Feature 161: 9.038460\n",
      "Feature 162: 52.172285\n",
      "Feature 163: 22.002640\n",
      "Feature 164: 185.556980\n",
      "Feature 165: 208.654181\n",
      "Feature 166: 42.060839\n",
      "Feature 167: 6.377808\n",
      "Feature 168: 149.858299\n",
      "Feature 169: 1659.406907\n",
      "Feature 170: 31.375364\n",
      "Feature 171: 5.348111\n",
      "Feature 172: 81.846936\n",
      "Feature 173: 3.260351\n",
      "Feature 174: 0.291722\n",
      "Feature 175: 0.039959\n",
      "Feature 176: 713.879289\n",
      "Feature 177: 526.493347\n",
      "Feature 178: 73.151868\n",
      "Feature 179: 176.178412\n",
      "Feature 180: 0.145547\n",
      "Feature 181: 5.532697\n",
      "Feature 182: 65.783840\n",
      "Feature 183: 8.809524\n",
      "Feature 184: 46.181813\n",
      "Feature 185: 0.024444\n",
      "Feature 186: 1.133398\n",
      "Feature 187: 35.244110\n",
      "Feature 188: 75.257572\n",
      "Feature 189: 301.792001\n",
      "Feature 190: 591.659257\n",
      "Feature 191: 92.902421\n",
      "Feature 192: 105.514347\n",
      "Feature 193: 19.610376\n",
      "Feature 194: 37.648459\n",
      "Feature 195: 52.088717\n",
      "Feature 196: 67.800254\n",
      "Feature 197: 49.415066\n",
      "Feature 198: 34.220735\n",
      "Feature 199: 12.130819\n",
      "Feature 200: 24.247437\n",
      "Feature 201: 283.834539\n",
      "Feature 202: 58.942112\n",
      "Feature 203: 0.040264\n",
      "Feature 204: 204.866253\n",
      "Feature 205: 511.316197\n",
      "Feature 206: 10.464362\n",
      "Feature 207: 67.913397\n",
      "Feature 208: 303.401358\n",
      "Feature 209: 1.374723\n",
      "Feature 210: 79.584638\n",
      "Feature 211: 10.975337\n",
      "Feature 212: 256.393603\n",
      "Feature 213: 176.156796\n",
      "Feature 214: 176.156796\n",
      "Feature 215: 90.375663\n",
      "Feature 216: 330.795539\n",
      "Feature 217: 39.245070\n",
      "Feature 218: 3.540643\n",
      "Feature 219: 176.156796\n",
      "Feature 220: 1.748285\n",
      "Feature 221: 178.167627\n",
      "Feature 222: 42.606970\n",
      "Feature 223: 0.046721\n",
      "Feature 224: 176.156796\n",
      "Feature 225: 5.355508\n",
      "Feature 226: 225.582928\n",
      "Feature 227: 319.791966\n",
      "Feature 228: 46.663838\n",
      "Feature 229: 545.471032\n",
      "Feature 230: 0.423622\n",
      "Feature 231: 176.156796\n",
      "Feature 232: 203.444336\n",
      "Feature 233: 76.563765\n",
      "Feature 234: 48.672543\n",
      "Feature 235: 46.088304\n",
      "Feature 236: 422.368236\n",
      "Feature 237: 13.419780\n",
      "Feature 238: 143.352269\n",
      "Feature 239: 164.224001\n",
      "Feature 240: 367.633712\n",
      "Feature 241: 2.392399\n",
      "Feature 242: 4.061240\n",
      "Feature 243: 0.658859\n",
      "Feature 244: 0.065317\n",
      "Feature 245: 1.236985\n",
      "Feature 246: 0.204627\n",
      "Feature 247: 0.508098\n",
      "Feature 248: 0.565863\n",
      "Feature 249: 3.335521\n",
      "Feature 250: 185.533475\n",
      "Feature 251: 70.345948\n",
      "Feature 252: 6.247791\n",
      "Feature 253: 0.896421\n",
      "Feature 254: 3.016389\n",
      "Feature 255: 15.343174\n",
      "Feature 256: 179.566947\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 223 important features\n"
     ]
    }
   ],
   "source": [
    "fs_imp_feat = []\n",
    "for feat,weight in zip(x_train.columns, fs.scores_):\n",
    "    if abs(weight) > 1:\n",
    "        fs_imp_feat.append(feat)\n",
    "print('There are %d important features' %(len(fs_imp_feat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3 = x_train[fs_imp_feat]\n",
    "\n",
    "feat_box_cox = [i for i in fs_imp_feat if i in to_box_cox]\n",
    "feat_yeo_j = [i for i in fs_imp_feat if i in to_yeoj]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "            transformers = [\n",
    "                            ('box-cox', PowerTransformer(method='box-cox'), feat_box_cox),\n",
    "                            ('yeo-j', PowerTransformer(method='yeo-johnson'), feat_yeo_j),\n",
    "            ], remainder='passthrough'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'lasso__alpha': 0.00022567751788824385}\n",
      "Best Score:  0.11858522972581724\n"
     ]
    }
   ],
   "source": [
    "model = Lasso(random_state=42)\n",
    "params = {\n",
    "    'lasso__alpha': loguniform(1e-6, 10)\n",
    "        }\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "grid_search.fit(x_train_3, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'ridge__alpha': 7.673614226991978, 'ridge__solver': 'cholesky'}\n",
      "Best Score:  0.1180818425462436\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "params = {\n",
    "    'ridge__alpha': loguniform(1e-6, 10),\n",
    "    'ridge__solver': ('auto', 'svd', 'cholesky', 'saga')\n",
    "        }\n",
    "\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "grid_search.fit(x_train_3, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBRegressor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=41, objective ='reg:squarederror', verbosity=0)\n",
    "params = {\n",
    "    'xgbregressor__n_estimators': (1000, 1500, 2000, 25000, 3000),\n",
    "    'xgbregressor__learning_rate': loguniform(5e-4, 0.5),\n",
    "    'xgbregressor__gamma': uniform(0.05, 0.5),\n",
    "    'xgbregressor__reg_alpha': uniform(0.1, 1),\n",
    "    'xgbregressor__reg_lambda': uniform(0.1, 1),\n",
    "    'xgbregressor__max_depth': (3, 4)\n",
    "        }\n",
    "# pipeline = make_pipeline(preprocess, model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "# grid_search.fit(x_train_3, y_train)\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'xgbregressor__gamma': 0.1009453491763986, 'xgbregressor__learning_rate': 0.012526579470894885, 'xgbregressor__max_depth': 4, 'xgbregressor__n_estimators': 1000, 'xgbregressor__reg_alpha': 0.7588036210260883, 'xgbregressor__reg_lambda': 0.6174635714797791}\n",
    "\n",
    "Best Score:  0.13611994569339628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ElasticNet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'elasticnet__alpha': 0.00040723826086807473, 'elasticnet__l1_ratio': 0.8514267753409143}\n",
      "Best Score:  0.11855306996211713\n"
     ]
    }
   ],
   "source": [
    "model = ElasticNet()\n",
    "params = {\n",
    "    'elasticnet__alpha': loguniform(1e-5, 10),\n",
    "    'elasticnet__l1_ratio': uniform(0, 1),\n",
    "        }\n",
    "pipeline = make_pipeline(preprocess, RobustScaler(), model)\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "grid_search.fit(x_train_3, y_train)\n",
    "print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LGBM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(objective='regression', verbosity=-1)\n",
    "params = {\n",
    "    'lgbmregressor__learning_rate': uniform(1e-3, 1),\n",
    "    'lgbmregressor__n_estimators': (500, 600, 700, 800, 1000),\n",
    "    'lgbmregressor__bagging_fraction': uniform(0, 0.99),\n",
    "    'lgbmregressor__bagging_fraction': uniform(0, 0.99),\n",
    "    'lgbmregressor__num_leaves': (25, 31, 40),\n",
    "    'lgbmregressor__reg_lambda': uniform(1e-7, 1e-3),\n",
    "    'lgbmregressor__min_sum_hessian_in_leaf': uniform(1e-3, 1),\n",
    "        }\n",
    "# pipeline = make_pipeline(model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=30)\n",
    "# grid_search.fit(x_train_3, y_train)\n",
    "# print('\\n')\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'lgbmregressor__bagging_fraction': 0.06034189808825029, 'lgbmregressor__learning_rate': 0.03192014698207368, 'lgbmregressor__min_sum_hessian_in_leaf': 0.08745660665621446, 'lgbmregressor__n_estimators': 700, 'lgbmregressor__num_leaves': 31, 'lgbmregressor__reg_lambda': 0.00022785578936763008}\n",
    "\n",
    "Best Score:  0.13080664293646999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoostRegressor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(eval_metric='RMSE', verbose=False)\n",
    "params = {\n",
    "    'catboostregressor__iterations': (1000, 2000, 3000),\n",
    "    'catboostregressor__learning_rate': uniform(5e-4, 5e-1),\n",
    "    'catboostregressor__depth': (4, 6, 10),\n",
    "    'catboostregressor__l2_leaf_reg': (1, 2, 3, 5, 9),\n",
    "        }\n",
    "# pipeline = make_pipeline(model)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(pipeline, params, scoring=neg_rmse, cv=kf, n_iter=20)\n",
    "# grid_search.fit(x_train_3, y_train)\n",
    "# print('Best Hyperparameters: %s' %grid_search.best_params_)\n",
    "# print('Best Score: ', -1.0*grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected output:*\n",
    "\n",
    "Best Hyperparameters: {'catboostregressor__depth': 4, 'catboostregressor__iterations': 2000, 'catboostregressor__l2_leaf_reg': 1, 'catboostregressor__learning_rate': 0.04309830749433374}\n",
    "\n",
    "Best Score:  0.12055602904682879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
